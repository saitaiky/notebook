

# What is big data

Big data is a term for a group of datasets so massive and sophisticated that it becomes troublesome to process using on-hand database-management tools or contemporary processing applications. Within the recent market, massive data trends to refer to the employment of user-behavior analytics, predictive analytics, or certain different advanced data-analysis methods that extract value from this new data echo system analytics.

### Characteristics

- Volume(size): Big data implies massive amounts of data. The size of data gets a very relevant role in determining the value out of the data, and it is also a key factor that determines whether we can judge the chunk of data as big. Hence, volume justifies one of the important attributes of big data.
- Velocity(speed): This refers to the increasing speed at which large amounts of data are generated, stored, and analyzed. Real-time processing is a key goal, allowing data to be processed as it is produced.
- Variety(Complexity): Big data encompasses diverse types of structured, semi-structured, and unstructured data from various sources. This diversity adds complexity to data storage, processing, and integration.
- Veracity(Quality): Veracity relates to the quality and accuracy of data. Big data can be noisy and uncertain, posing challenges in ensuring data accuracy and validity for meaningful analysis.
- Valence(Connectedness): Valence represents the connectedness of data, with higher valence indicating denser connections. This affects the efficiency of data analysis.

### 3 sources of big data

- Machine-Generated Logs: Data generated by real-time sensors in industrial machinery, vehicles, environmental sensors, and personal health trackers. This data includes click-log stream data (user interactions on websites), gaming events log data (user actions in online games), sensors log data (RFID, smart meters, sensors in devices), weblog event data (data from applications, servers, and networks), and point-of-sale event-log data (product sales patterns in retail).
- Person-Generated Logs: Data generated by individuals on social media platforms, including status updates, tweets, photos, and media uploads. This user-generated content provides insights into communication and interaction patterns, which can be used for personalized recommendations and sentiment analysis. The data is often unstructured and can be in text, PDF, CSV, or JSON formats.
- Organization-Generated Data: Data generated by organizations, including transaction information stored in databases and structured data in data warehouses. This highly structured data comes from various sources like SQL, Oracle, and MS Access databases. It is utilized for business intelligence and market analysis through information and communication technology (ICT) processing.

## Data modeling

Big data modeling refers to the process of designing and creating data models that can effectively handle and represent large volumes of diverse and complex data in a way that supports **efficient storage, processing, and analysis**. It involves structuring and organizing the data in a manner that allows for meaningful insights to be derived from the massive and heterogeneous datasets that characterize big data.

We can hold at least two primary reasons for performing data modeling:
- Strategic data modeling facilitates the overall information systems development strategy
- Data modeling can help in the development of new databases









---

# see which part to add

A high-level data model utilizes simplistic graphical images to illustrate the core concepts and principles of an organization and what they mean. A database model shows the logical structure of a database, including the relationships and constraints that determine how data can be stored and accessed.


## Do chapter 2 later